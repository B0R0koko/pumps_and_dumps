{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from typing import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "\n",
    "ROOT_DIR = Path(os.getcwd()).parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_pumped\n",
       "False    40711\n",
       "True       355\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df: pd.DataFrame = pd.read_parquet(\n",
    "    os.path.join(ROOT_DIR, \"data/datasets/train_13_06.parquet\")\n",
    ")\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df[\"pump_hash\"] = df[\"pumped_ticker\"] + \"_\" + df[\"pump_time\"]\n",
    "df[\"is_pumped\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Fill nans</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>volume_std_1h_SLR</th>\n",
       "      <td>41066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volume_quote_std_1h_SLR</th>\n",
       "      <td>41066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_return_std_1h</th>\n",
       "      <td>41066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_1h</th>\n",
       "      <td>4051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_3h</th>\n",
       "      <td>1292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_6h</th>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_long_share_1h_24h</th>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_12h</th>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_return_std_3h</th>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_24h</th>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_return_std_6h</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_return_std_12h</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_long_share_1h_72h</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_long_share_72h_72h</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_long_share_3h_72h</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_long_share_60h_72h</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_long_share_6h_72h</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_long_share_48h_72h</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_long_share_12h_72h</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_long_share_24h_72h</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_48h</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_60h</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_share_60h_72h</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_share_3h_72h</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_share_72h_72h</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_share_6h_72h</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_share_1h_72h</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_72h</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_share_48h_72h</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_share_24h_72h</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_share_12h_72h</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_return_std_24h</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_listed</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pumped</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_long_trades_share_1h_24h</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pump_time</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_trades_share_1h_24h</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volume_quote_imbalance_3h</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_prev_pumps</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0\n",
       "volume_std_1h_SLR                  41066\n",
       "volume_quote_std_1h_SLR            41066\n",
       "log_return_std_1h                  41066\n",
       "quote_slippage_imbalance_1h         4051\n",
       "quote_slippage_imbalance_3h         1292\n",
       "quote_slippage_imbalance_6h          606\n",
       "quote_slippage_long_share_1h_24h     314\n",
       "quote_slippage_imbalance_12h         281\n",
       "log_return_std_3h                    162\n",
       "quote_slippage_imbalance_24h         113\n",
       "log_return_std_6h                     91\n",
       "log_return_std_12h                    86\n",
       "quote_slippage_long_share_1h_72h      55\n",
       "quote_slippage_long_share_72h_72h     55\n",
       "quote_slippage_long_share_3h_72h      54\n",
       "quote_slippage_long_share_60h_72h     53\n",
       "quote_slippage_long_share_6h_72h      52\n",
       "quote_slippage_long_share_48h_72h     51\n",
       "quote_slippage_long_share_12h_72h     50\n",
       "quote_slippage_long_share_24h_72h     49\n",
       "quote_slippage_imbalance_48h          29\n",
       "quote_slippage_imbalance_60h          13\n",
       "quote_slippage_share_60h_72h          11\n",
       "quote_slippage_share_3h_72h           11\n",
       "quote_slippage_share_72h_72h          11\n",
       "quote_slippage_share_6h_72h           11\n",
       "quote_slippage_share_1h_72h           11\n",
       "quote_slippage_imbalance_72h          10\n",
       "quote_slippage_share_48h_72h          10\n",
       "quote_slippage_share_24h_72h          10\n",
       "quote_slippage_share_12h_72h          10\n",
       "log_return_std_24h                     1\n",
       "days_listed                            0\n",
       "is_pumped                              0\n",
       "ticker                                 0\n",
       "num_long_trades_share_1h_24h           0\n",
       "pump_time                              0\n",
       "num_trades_share_1h_24h                0\n",
       "volume_quote_imbalance_3h              0\n",
       "num_prev_pumps                         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sort_values(ascending=False).to_frame().head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_cols = df.columns[:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in nans with zeros for other cols\n",
    "\n",
    "df[reg_cols] = df[reg_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in nans with median values\n",
    "df_features: pd.DataFrame = pd.DataFrame()\n",
    "\n",
    "for (pumped_ticker, pump_time), df_pump in df.groupby([\"pumped_ticker\", \"pump_time\"]):\n",
    "    pump_has_nans: bool = df_pump[df_pump[\"ticker\"] == pumped_ticker][cols_fill_median].isna().any().any()\n",
    "\n",
    "    if pump_has_nans:\n",
    "        continue\n",
    "\n",
    "    for col in cols_fill_median:\n",
    "        df_pump[col] = df_pump[col].fillna(df_pump[col].median())\n",
    "\n",
    "    df_features = pd.concat([df_features, df_pump])\n",
    "\n",
    "df_features[\"is_pumped\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pumps: pd.DataFrame = pd.DataFrame()\n",
    "\n",
    "for i, (pump_hash, df_pump) in enumerate(df_features.groupby(\"pump_hash\")):\n",
    "    if i < 3:\n",
    "        df_pumps = pd.concat([df_pumps, df_pump])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=10, ncols=5, figsize=(30, 15))\n",
    "axs = [el for ax in axs for el in ax]\n",
    "\n",
    "for ax, col in tqdm(zip(axs, reg_cols[50:100]), total=len(reg_cols[50:100])):\n",
    "    try:\n",
    "        sns.histplot(\n",
    "            data=df_pumps, x=col, hue=\"pump_hash\", alpha=.3, legend=False, ax=ax, kde=True\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Apply crosssectional normalization</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg_cols = list(set(reg_cols) - set(cols_fill_median))\n",
    "\n",
    "df_features = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_norm: pd.DataFrame = pd.DataFrame()\n",
    "cols_to_standardize: List[str] = list(set(reg_cols) - set([\"num_prev_pumps\"]))\n",
    "\n",
    "for pump_hash, df_pump in df_features.groupby(\"pump_hash\"):\n",
    "    for col in cols_to_standardize:\n",
    "        df_pump[col] = (df_pump[col] - df_pump[col].mean()) / df_pump[col].std()\n",
    "\n",
    "    df_features_norm = pd.concat([df_features_norm, df_pump])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train: pd.DataFrame = df_features_norm[\n",
    "    df_features_norm[\"pump_time\"] < \"2020-05-01\"\n",
    "].copy()\n",
    "\n",
    "df_test: pd.DataFrame = df_features_norm[\n",
    "    df_features_norm[\"pump_time\"] >= \"2020-05-01\"\n",
    "].copy()\n",
    "\n",
    "df_train[\"is_pumped\"].value_counts(), df_test[\"is_pumped\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Train the model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, precision_recall_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "from functools import partial\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "\n",
    "import optuna\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Vanilla CatboostClassifier</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train: Pool = Pool(data=df_train[reg_cols], label=df_train[\"is_pumped\"], cat_features=[\"num_prev_pumps\"])\n",
    "test: Pool = Pool(data=df_test[reg_cols], label=df_test[\"is_pumped\"], cat_features=[\"num_prev_pumps\"])\n",
    "\n",
    "model_baseline = CatBoostClassifier(\n",
    "    objective=\"Logloss\", iterations=200, verbose=100\n",
    ")\n",
    "model_baseline.fit(train)\n",
    "\n",
    "y_proba: np.array = model_baseline.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"proba\"] = y_proba[:, 1]\n",
    "\n",
    "thresholds = range(1, 301)\n",
    "baseline_top_k_vals = []\n",
    "\n",
    "for K in thresholds: \n",
    "\n",
    "    top_k: List[bool] = []\n",
    "\n",
    "    for pump_hash, df_pump in df_test.groupby(\"pump_hash\"):\n",
    "        df_pump = df_pump.sort_values(by=\"proba\", ascending=False)\n",
    "        top_k_contains_pump: bool = df_pump.iloc[:K][\"is_pumped\"].any()\n",
    "        top_k.append(top_k_contains_pump)\n",
    "\n",
    "    baseline_top_k_vals.append(\n",
    "        sum(top_k) / len(top_k)\n",
    "    )\n",
    "\n",
    "auc(x=np.linspace(0, 1, 300), y=baseline_top_k_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thresholds, baseline_top_k_vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Optimize for Top-K AUC</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_top_k_auc(df_test: pd.DataFrame, y_proba: np.array) -> Tuple[float, np.array]:\n",
    "    \"\"\"Returns the area under the TOP-K curve\"\"\"\n",
    "    df_test: pd.DataFrame = df_test.copy()\n",
    "    df_test[\"proba\"] = y_proba\n",
    "\n",
    "    thresholds = range(1, 301)\n",
    "    top_k_vals = []\n",
    "\n",
    "    for K in thresholds: \n",
    "\n",
    "        top_k: List[bool] = []\n",
    "\n",
    "        for pump_hash, df_pump in df_test.groupby(\"pump_hash\"):\n",
    "            df_pump = df_pump.sort_values(by=\"proba\", ascending=False)\n",
    "            top_k_contains_pump: bool = df_pump.iloc[:K][\"is_pumped\"].any()\n",
    "            top_k.append(top_k_contains_pump)\n",
    "\n",
    "        top_k_vals.append(\n",
    "            sum(top_k) / len(top_k)\n",
    "        )\n",
    "\n",
    "    return auc(x=np.linspace(0, 1, 300), y=top_k_vals), top_k_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_objective(\n",
    "    trial: optuna.Trial, df: pd.DataFrame, reg_cols: List[str], target: str, fold: TimeSeriesSplit\n",
    ") -> float:\n",
    "    params = {\n",
    "        \"objective\": \"Logloss\",\n",
    "        \"eval_metric\": \"Logloss\",\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "        \"class_weights\": [1, trial.suggest_float(\"scale_pos_weight\", 1, 300)],\n",
    "    }\n",
    "\n",
    "    auc_scores = []\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for train_idx, val_idx in fold.split(df[reg_cols], df[target]):\n",
    "        # split data to train and validation sets\n",
    "        df_train, df_val = df.iloc[train_idx], df.iloc[val_idx]\n",
    "        # train on train subset and use validation set to evaluate the model\n",
    "        train = Pool(data=df_train[reg_cols], label=df_train[target], cat_features=[\"num_prev_pumps\"])\n",
    "        val = Pool(data=df_val[reg_cols], label=df_val[target], cat_features=[\"num_prev_pumps\"])\n",
    "        \n",
    "        # Fit the model with early stopping\n",
    "        model = CatBoostClassifier(\n",
    "            **params, \n",
    "            iterations=500,\n",
    "            early_stopping_rounds=20,\n",
    "            use_best_model=True,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        model.fit(train, eval_set=val)\n",
    "        \n",
    "        y_proba = model.predict_proba(val)[:, 1]\n",
    "        top_k_auc, _ = calc_top_k_auc(df_test=df_val, y_proba=y_proba)\n",
    "        \n",
    "        # get the best auc_score validation set\n",
    "        auc_scores.append(top_k_auc)\n",
    "        \n",
    "        trial.report(top_k_auc, i)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        \n",
    "        del model, train, val\n",
    "        _ = gc.collect()\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    return np.mean(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "study_catboost = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5)\n",
    ")\n",
    "\n",
    "study_catboost.optimize(\n",
    "    partial(catboost_objective, df=df_train, reg_cols=reg_cols, target=\"is_pumped\", fold=fold), \n",
    "    n_trials=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"Logloss\",\n",
    "    # \"task_type\": \"GPU\"\n",
    "}\n",
    "\n",
    "cb_params = {\n",
    "    \"objective\": \"Logloss\",\n",
    "    # \"task_type\": \"GPU\"\n",
    "}\n",
    "\n",
    "cb_params.update(study_catboost.best_params)\n",
    "cb_params[\"class_weights\"] = [1, study_catboost.best_params[\"scale_pos_weight\"]]\n",
    "\n",
    "del cb_params[\"scale_pos_weight\"]\n",
    "\n",
    "cb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    # **cb_params,\n",
    "    iterations=300,\n",
    "    # early_stopping_rounds=20,\n",
    "    # use_best_model=True,\n",
    "    verbose=100\n",
    ")\n",
    "model.fit(\n",
    "    train, \n",
    "    # eval_set=val\n",
    ")\n",
    "\n",
    "y_proba: np.array = model.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_auc, top_k_vals = calc_top_k_auc(df_test, y_proba=y_proba)\n",
    "\n",
    "plt.plot(np.linspace(0, 1, 300), baseline_top_k_vals, label=\"Baseline model\")\n",
    "plt.plot(np.linspace(0, 1, 300), top_k_vals, label=f\"Tuned Catboost: {round(top_k_auc, 4)}\")\n",
    "\n",
    "plt.title(\"TOP-K AUC\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "y_pred = (y_proba >= 0.05).astype(int)\n",
    "\n",
    "print(classification_report(y_true=df_test[\"is_pumped\"], y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_pred=y_pred, y_true=df_test[\"is_pumped\"])\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc, PrecisionRecallDisplay\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_true=df_test[\"is_pumped\"], probas_pred=y_proba)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "PrecisionRecallDisplay(\n",
    "    precision=precision, recall=recall\n",
    ").plot(ax=ax)\n",
    "\n",
    "f_scores = np.linspace(0.1, 0.8, num=10)\n",
    "lines, labels = [], []\n",
    "\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y = f_score * x / (2 * x - f_score)\n",
    "    (l,) = ax.plot(x[y >= 0], y[y >= 0], color=\"blue\", alpha=0.2)\n",
    "    ax.annotate(\"f1={0:0.1f}\".format(f_score), xy=(0.9, y[45] + 0.02))\n",
    "\n",
    "plt.title(f\"AUC score: {round(auc(recall, precision), 5)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP-K metric\n",
    "df_test[\"proba\"] = y_proba\n",
    "\n",
    "top_k_vals = []\n",
    "\n",
    "for K in [1, 5, 10, 20, 40, 70]: \n",
    "\n",
    "    top_k: List[bool] = []\n",
    "\n",
    "    for pump_hash, df_pump in df_test.groupby(\"pump_hash\"):\n",
    "        df_pump = df_pump.sort_values(by=\"proba\", ascending=False)\n",
    "        top_k_contains_pump: bool = df_pump.iloc[:K][\"is_pumped\"].any()\n",
    "        top_k.append(top_k_contains_pump)\n",
    "\n",
    "    top_k_vals.append(\n",
    "        sum(top_k) / len(top_k)\n",
    "    )\n",
    "        \n",
    "top_k_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fi = pd.DataFrame({\n",
    "    \"features\": reg_cols,\n",
    "    \"feature_importance\": model.feature_importances_\n",
    "})\n",
    "\n",
    "df_fi = df_fi.sort_values(by=\"feature_importance\", ascending=False)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax1, ax2 = axs\n",
    "\n",
    "sns.barplot(\n",
    "    data=df_fi.iloc[:50], x=\"feature_importance\", y=\"features\", ax=ax1\n",
    ")\n",
    "sns.barplot(\n",
    "    data=df_fi.iloc[-50:], x=\"feature_importance\", y=\"features\", ax=ax2\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
