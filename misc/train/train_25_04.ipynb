{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from typing import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "\n",
    "ROOT_DIR = Path(os.getcwd()).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_pumped\n",
       "False    19534\n",
       "True       136\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df: pd.DataFrame = pd.read_parquet(\n",
    "    os.path.join(ROOT_DIR, \"data/datasets/train_01_05.parquet\")\n",
    ")\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df[\"pump_hash\"] = df[\"pumped_ticker\"] + \"_\" + df[\"pump_time\"]\n",
    "df[\"is_pumped\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Fill nans</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_ratio_1h_std_14d</th>\n",
       "      <td>2884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_ratio_1h_std_7d</th>\n",
       "      <td>1791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_ratio_1h</th>\n",
       "      <td>1506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_ratio_1h_std_3d</th>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_ratio_1h_mean_14d</th>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_ratio_3h</th>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_ratio_1h_std_1d</th>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_ratio_1h_mean_7d</th>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_ratio_7h</th>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_trades_ratio_1h</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_abs_long_ratio_1h_1d</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imbalance_ratio_1h</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_quote_abs_ratio_1h</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_ratio_12h</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_ratio_1h_mean_3d</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_ratio_1h_mean_1d</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_ratio_3h_1d</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_ratio_1h_overall_1d</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_ratio_1h_1d</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_ratio_7h_1d</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_ratio_12h_1d</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imbalance_ratio_3h</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_quote_abs_ratio_3h</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_trades_ratio_3h</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_abs_long_ratio_3h_1d</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_imbalance_ratio_1h_overall_3d</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imbalance_ratio_7h</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_trades_ratio_7h</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_slippage_quote_abs_ratio_7h</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote_abs_long_ratio_7h_1d</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_99_short_99_ratio_7d</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empty_trading_minutes_ratio_7d</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empty_trading_minutes_ratio_3d</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_whale_median_ratio_3d</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_whale_99_ratio_7d</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_whale_99_ratio_7d</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_whale_short_whale_ratio_7d</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_99_long_95_ratio_7d</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_99_long_95_ratio_14d</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_99_95_ratio_7d</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 0\n",
       "quote_slippage_imbalance_ratio_1h_std_14d     2884\n",
       "quote_slippage_imbalance_ratio_1h_std_7d      1791\n",
       "quote_slippage_imbalance_ratio_1h             1506\n",
       "quote_slippage_imbalance_ratio_1h_std_3d       894\n",
       "quote_slippage_imbalance_ratio_1h_mean_14d     702\n",
       "quote_slippage_imbalance_ratio_3h              470\n",
       "quote_slippage_imbalance_ratio_1h_std_1d       418\n",
       "quote_slippage_imbalance_ratio_1h_mean_7d      253\n",
       "quote_slippage_imbalance_ratio_7h              163\n",
       "long_trades_ratio_1h                           105\n",
       "quote_abs_long_ratio_1h_1d                     105\n",
       "imbalance_ratio_1h                             105\n",
       "quote_slippage_quote_abs_ratio_1h              105\n",
       "quote_slippage_imbalance_ratio_12h              91\n",
       "quote_slippage_imbalance_ratio_1h_mean_3d       75\n",
       "quote_slippage_imbalance_ratio_1h_mean_1d       46\n",
       "quote_slippage_ratio_3h_1d                      38\n",
       "quote_slippage_imbalance_ratio_1h_overall_1d    38\n",
       "quote_slippage_ratio_1h_1d                      37\n",
       "quote_slippage_ratio_7h_1d                      37\n",
       "quote_slippage_ratio_12h_1d                     37\n",
       "imbalance_ratio_3h                              20\n",
       "quote_slippage_quote_abs_ratio_3h               20\n",
       "long_trades_ratio_3h                            20\n",
       "quote_abs_long_ratio_3h_1d                      20\n",
       "quote_slippage_imbalance_ratio_1h_overall_3d     5\n",
       "imbalance_ratio_7h                               4\n",
       "long_trades_ratio_7h                             4\n",
       "quote_slippage_quote_abs_ratio_7h                4\n",
       "quote_abs_long_ratio_7h_1d                       4\n",
       "long_99_short_99_ratio_7d                        0\n",
       "empty_trading_minutes_ratio_7d                   0\n",
       "empty_trading_minutes_ratio_3d                   0\n",
       "short_whale_median_ratio_3d                      0\n",
       "long_whale_99_ratio_7d                           0\n",
       "short_whale_99_ratio_7d                          0\n",
       "long_whale_short_whale_ratio_7d                  0\n",
       "long_99_long_95_ratio_7d                         0\n",
       "long_99_long_95_ratio_14d                        0\n",
       "short_99_95_ratio_7d                             0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sort_values(ascending=False).to_frame().head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote_slippage_imbalance_ratio_12h</th>\n",
       "      <th>quote_slippage_quote_abs_ratio_12h</th>\n",
       "      <th>num_prev_pumps</th>\n",
       "      <th>exchange</th>\n",
       "      <th>pumped_ticker</th>\n",
       "      <th>pump_time</th>\n",
       "      <th>ticker</th>\n",
       "      <th>is_pumped</th>\n",
       "      <th>days_listed</th>\n",
       "      <th>pump_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0</td>\n",
       "      <td>binance</td>\n",
       "      <td>BRDBTC</td>\n",
       "      <td>2018-12-22 17:00:00</td>\n",
       "      <td>VIBBTC</td>\n",
       "      <td>False</td>\n",
       "      <td>418</td>\n",
       "      <td>BRDBTC_2018-12-22 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.683209</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0</td>\n",
       "      <td>binance</td>\n",
       "      <td>BRDBTC</td>\n",
       "      <td>2018-12-22 17:00:00</td>\n",
       "      <td>NULSUSDT</td>\n",
       "      <td>False</td>\n",
       "      <td>152</td>\n",
       "      <td>BRDBTC_2018-12-22 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.084946</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0</td>\n",
       "      <td>binance</td>\n",
       "      <td>BRDBTC</td>\n",
       "      <td>2018-12-22 17:00:00</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>False</td>\n",
       "      <td>492</td>\n",
       "      <td>BRDBTC_2018-12-22 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.671166</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0</td>\n",
       "      <td>binance</td>\n",
       "      <td>BRDBTC</td>\n",
       "      <td>2018-12-22 17:00:00</td>\n",
       "      <td>GVTBTC</td>\n",
       "      <td>False</td>\n",
       "      <td>401</td>\n",
       "      <td>BRDBTC_2018-12-22 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.159345</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>0</td>\n",
       "      <td>binance</td>\n",
       "      <td>BRDBTC</td>\n",
       "      <td>2018-12-22 17:00:00</td>\n",
       "      <td>REQBTC</td>\n",
       "      <td>False</td>\n",
       "      <td>421</td>\n",
       "      <td>BRDBTC_2018-12-22 17:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quote_slippage_imbalance_ratio_12h  quote_slippage_quote_abs_ratio_12h  \\\n",
       "0                            0.006160                            0.000284   \n",
       "1                            0.683209                            0.002124   \n",
       "2                            0.084946                            0.000107   \n",
       "3                           -0.671166                            0.001180   \n",
       "4                           -0.159345                            0.001340   \n",
       "\n",
       "   num_prev_pumps exchange pumped_ticker            pump_time    ticker  \\\n",
       "0               0  binance        BRDBTC  2018-12-22 17:00:00    VIBBTC   \n",
       "1               0  binance        BRDBTC  2018-12-22 17:00:00  NULSUSDT   \n",
       "2               0  binance        BRDBTC  2018-12-22 17:00:00   ETHUSDT   \n",
       "3               0  binance        BRDBTC  2018-12-22 17:00:00    GVTBTC   \n",
       "4               0  binance        BRDBTC  2018-12-22 17:00:00    REQBTC   \n",
       "\n",
       "   is_pumped  days_listed                   pump_hash  \n",
       "0      False          418  BRDBTC_2018-12-22 17:00:00  \n",
       "1      False          152  BRDBTC_2018-12-22 17:00:00  \n",
       "2      False          492  BRDBTC_2018-12-22 17:00:00  \n",
       "3      False          401  BRDBTC_2018-12-22 17:00:00  \n",
       "4      False          421  BRDBTC_2018-12-22 17:00:00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:5, -10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_cols = df.columns[:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in nans with zeros for other cols\n",
    "\n",
    "df[reg_cols] = df[reg_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_fill_median = [\n",
    "    \"daily_exchange_volume_share_3d_mean\",\n",
    "    \"daily_exchange_volume_share_7d_mean\",\n",
    "    \"daily_exchange_volume_share_14d_mean\",\n",
    "    \"daily_exchange_volume_share_30d_mean\",\n",
    "    \"daily_exchange_volume_share_30d_std\",\n",
    "    \"daily_exchange_volume_share_3d_std\",\n",
    "    \"daily_exchange_volume_share_14d_std\",\n",
    "    \"daily_exchange_volume_share_7d_std\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['daily_exchange_volume_share_3d_mean',\\n       'daily_exchange_volume_share_7d_mean',\\n       'daily_exchange_volume_share_14d_mean',\\n       'daily_exchange_volume_share_30d_mean',\\n       'daily_exchange_volume_share_30d_std',\\n       'daily_exchange_volume_share_3d_std',\\n       'daily_exchange_volume_share_14d_std',\\n       'daily_exchange_volume_share_7d_std'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m df_features: pd\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (pumped_ticker, pump_time), df_pump \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpumped_ticker\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpump_time\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m----> 5\u001b[0m     pump_has_nans: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mdf_pump\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_pump\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mticker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpumped_ticker\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcols_fill_median\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39many()\u001b[38;5;241m.\u001b[39many()\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pump_has_nans:\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Pumps\\env\\Lib\\site-packages\\pandas\\core\\frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32md:\\Pumps\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32md:\\Pumps\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['daily_exchange_volume_share_3d_mean',\\n       'daily_exchange_volume_share_7d_mean',\\n       'daily_exchange_volume_share_14d_mean',\\n       'daily_exchange_volume_share_30d_mean',\\n       'daily_exchange_volume_share_30d_std',\\n       'daily_exchange_volume_share_3d_std',\\n       'daily_exchange_volume_share_14d_std',\\n       'daily_exchange_volume_share_7d_std'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# fill in nans with median values\n",
    "df_features: pd.DataFrame = pd.DataFrame()\n",
    "\n",
    "for (pumped_ticker, pump_time), df_pump in df.groupby([\"pumped_ticker\", \"pump_time\"]):\n",
    "    pump_has_nans: bool = df_pump[df_pump[\"ticker\"] == pumped_ticker][cols_fill_median].isna().any().any()\n",
    "\n",
    "    if pump_has_nans:\n",
    "        continue\n",
    "\n",
    "    for col in cols_fill_median:\n",
    "        df_pump[col] = df_pump[col].fillna(df_pump[col].median())\n",
    "\n",
    "    df_features = pd.concat([df_features, df_pump])\n",
    "\n",
    "df_features[\"is_pumped\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pump_hash'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m df_pumps: pd\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (pump_hash, df_pump) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mdf_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpump_hash\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m      5\u001b[0m         df_pumps \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_pumps, df_pump])\n",
      "File \u001b[1;32md:\\Pumps\\env\\Lib\\site-packages\\pandas\\core\\frame.py:9170\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   9167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   9168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 9170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9173\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9176\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Pumps\\env\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[1;32md:\\Pumps\\env\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'pump_hash'"
     ]
    }
   ],
   "source": [
    "df_pumps: pd.DataFrame = pd.DataFrame()\n",
    "\n",
    "for i, (pump_hash, df_pump) in enumerate(df_features.groupby(\"pump_hash\")):\n",
    "    if i < 3:\n",
    "        df_pumps = pd.concat([df_pumps, df_pump])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=10, ncols=5, figsize=(30, 15))\n",
    "axs = [el for ax in axs for el in ax]\n",
    "\n",
    "for ax, col in tqdm(zip(axs, reg_cols[50:100]), total=len(reg_cols[50:100])):\n",
    "    try:\n",
    "        sns.histplot(\n",
    "            data=df_pumps, x=col, hue=\"pump_hash\", alpha=.3, legend=False, ax=ax, kde=True\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Apply crosssectional normalization</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg_cols = list(set(reg_cols) - set(cols_fill_median))\n",
    "\n",
    "df_features = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_norm: pd.DataFrame = pd.DataFrame()\n",
    "cols_to_standardize: List[str] = list(set(reg_cols) - set([\"num_prev_pumps\"]))\n",
    "\n",
    "for pump_hash, df_pump in df_features.groupby(\"pump_hash\"):\n",
    "    for col in cols_to_standardize:\n",
    "        df_pump[col] = (df_pump[col] - df_pump[col].mean()) / df_pump[col].std()\n",
    "\n",
    "    df_features_norm = pd.concat([df_features_norm, df_pump])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train: pd.DataFrame = df_features_norm[\n",
    "    df_features_norm[\"pump_time\"] < \"2020-05-01\"\n",
    "].copy()\n",
    "\n",
    "df_test: pd.DataFrame = df_features_norm[\n",
    "    df_features_norm[\"pump_time\"] >= \"2020-05-01\"\n",
    "].copy()\n",
    "\n",
    "df_train[\"is_pumped\"].value_counts(), df_test[\"is_pumped\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Train the model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, precision_recall_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "from functools import partial\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "\n",
    "import optuna\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Vanilla CatboostClassifier</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train: Pool = Pool(data=df_train[reg_cols], label=df_train[\"is_pumped\"], cat_features=[\"num_prev_pumps\"])\n",
    "test: Pool = Pool(data=df_test[reg_cols], label=df_test[\"is_pumped\"], cat_features=[\"num_prev_pumps\"])\n",
    "\n",
    "model_baseline = CatBoostClassifier(\n",
    "    objective=\"Logloss\", iterations=200, verbose=100\n",
    ")\n",
    "model_baseline.fit(train)\n",
    "\n",
    "y_proba: np.array = model_baseline.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"proba\"] = y_proba[:, 1]\n",
    "\n",
    "thresholds = range(1, 301)\n",
    "baseline_top_k_vals = []\n",
    "\n",
    "for K in thresholds: \n",
    "\n",
    "    top_k: List[bool] = []\n",
    "\n",
    "    for pump_hash, df_pump in df_test.groupby(\"pump_hash\"):\n",
    "        df_pump = df_pump.sort_values(by=\"proba\", ascending=False)\n",
    "        top_k_contains_pump: bool = df_pump.iloc[:K][\"is_pumped\"].any()\n",
    "        top_k.append(top_k_contains_pump)\n",
    "\n",
    "    baseline_top_k_vals.append(\n",
    "        sum(top_k) / len(top_k)\n",
    "    )\n",
    "\n",
    "auc(x=np.linspace(0, 1, 300), y=baseline_top_k_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thresholds, baseline_top_k_vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Optimize for Top-K AUC</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_top_k_auc(df_test: pd.DataFrame, y_proba: np.array) -> Tuple[float, np.array]:\n",
    "    \"\"\"Returns the area under the TOP-K curve\"\"\"\n",
    "    df_test: pd.DataFrame = df_test.copy()\n",
    "    df_test[\"proba\"] = y_proba\n",
    "\n",
    "    thresholds = range(1, 301)\n",
    "    top_k_vals = []\n",
    "\n",
    "    for K in thresholds: \n",
    "\n",
    "        top_k: List[bool] = []\n",
    "\n",
    "        for pump_hash, df_pump in df_test.groupby(\"pump_hash\"):\n",
    "            df_pump = df_pump.sort_values(by=\"proba\", ascending=False)\n",
    "            top_k_contains_pump: bool = df_pump.iloc[:K][\"is_pumped\"].any()\n",
    "            top_k.append(top_k_contains_pump)\n",
    "\n",
    "        top_k_vals.append(\n",
    "            sum(top_k) / len(top_k)\n",
    "        )\n",
    "\n",
    "    return auc(x=np.linspace(0, 1, 300), y=top_k_vals), top_k_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_objective(\n",
    "    trial: optuna.Trial, df: pd.DataFrame, reg_cols: List[str], target: str, fold: TimeSeriesSplit\n",
    ") -> float:\n",
    "    params = {\n",
    "        \"objective\": \"Logloss\",\n",
    "        \"eval_metric\": \"Logloss\",\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "        \"class_weights\": [1, trial.suggest_float(\"scale_pos_weight\", 1, 300)],\n",
    "    }\n",
    "\n",
    "    auc_scores = []\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for train_idx, val_idx in fold.split(df[reg_cols], df[target]):\n",
    "        # split data to train and validation sets\n",
    "        df_train, df_val = df.iloc[train_idx], df.iloc[val_idx]\n",
    "        # train on train subset and use validation set to evaluate the model\n",
    "        train = Pool(data=df_train[reg_cols], label=df_train[target], cat_features=[\"num_prev_pumps\"])\n",
    "        val = Pool(data=df_val[reg_cols], label=df_val[target], cat_features=[\"num_prev_pumps\"])\n",
    "        \n",
    "        # Fit the model with early stopping\n",
    "        model = CatBoostClassifier(\n",
    "            **params, \n",
    "            iterations=500,\n",
    "            early_stopping_rounds=20,\n",
    "            use_best_model=True,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        model.fit(train, eval_set=val)\n",
    "        \n",
    "        y_proba = model.predict_proba(val)[:, 1]\n",
    "        top_k_auc, _ = calc_top_k_auc(df_test=df_val, y_proba=y_proba)\n",
    "        \n",
    "        # get the best auc_score validation set\n",
    "        auc_scores.append(top_k_auc)\n",
    "        \n",
    "        trial.report(top_k_auc, i)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        \n",
    "        del model, train, val\n",
    "        _ = gc.collect()\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    return np.mean(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "study_catboost = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5)\n",
    ")\n",
    "\n",
    "study_catboost.optimize(\n",
    "    partial(catboost_objective, df=df_train, reg_cols=reg_cols, target=\"is_pumped\", fold=fold), \n",
    "    n_trials=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"Logloss\",\n",
    "    # \"task_type\": \"GPU\"\n",
    "}\n",
    "\n",
    "cb_params = {\n",
    "    \"objective\": \"Logloss\",\n",
    "    # \"task_type\": \"GPU\"\n",
    "}\n",
    "\n",
    "cb_params.update(study_catboost.best_params)\n",
    "cb_params[\"class_weights\"] = [1, study_catboost.best_params[\"scale_pos_weight\"]]\n",
    "\n",
    "del cb_params[\"scale_pos_weight\"]\n",
    "\n",
    "cb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    # **cb_params,\n",
    "    iterations=300,\n",
    "    # early_stopping_rounds=20,\n",
    "    # use_best_model=True,\n",
    "    verbose=100\n",
    ")\n",
    "model.fit(\n",
    "    train, \n",
    "    # eval_set=val\n",
    ")\n",
    "\n",
    "y_proba: np.array = model.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_auc, top_k_vals = calc_top_k_auc(df_test, y_proba=y_proba)\n",
    "\n",
    "plt.plot(np.linspace(0, 1, 300), baseline_top_k_vals, label=\"Baseline model\")\n",
    "plt.plot(np.linspace(0, 1, 300), top_k_vals, label=f\"Tuned Catboost: {round(top_k_auc, 4)}\")\n",
    "\n",
    "plt.title(\"TOP-K AUC\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "y_pred = (y_proba >= 0.05).astype(int)\n",
    "\n",
    "print(classification_report(y_true=df_test[\"is_pumped\"], y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_pred=y_pred, y_true=df_test[\"is_pumped\"])\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc, PrecisionRecallDisplay\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_true=df_test[\"is_pumped\"], probas_pred=y_proba)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "PrecisionRecallDisplay(\n",
    "    precision=precision, recall=recall\n",
    ").plot(ax=ax)\n",
    "\n",
    "f_scores = np.linspace(0.1, 0.8, num=10)\n",
    "lines, labels = [], []\n",
    "\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y = f_score * x / (2 * x - f_score)\n",
    "    (l,) = ax.plot(x[y >= 0], y[y >= 0], color=\"blue\", alpha=0.2)\n",
    "    ax.annotate(\"f1={0:0.1f}\".format(f_score), xy=(0.9, y[45] + 0.02))\n",
    "\n",
    "plt.title(f\"AUC score: {round(auc(recall, precision), 5)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP-K metric\n",
    "df_test[\"proba\"] = y_proba\n",
    "\n",
    "top_k_vals = []\n",
    "\n",
    "for K in [1, 5, 10, 20, 40, 70]: \n",
    "\n",
    "    top_k: List[bool] = []\n",
    "\n",
    "    for pump_hash, df_pump in df_test.groupby(\"pump_hash\"):\n",
    "        df_pump = df_pump.sort_values(by=\"proba\", ascending=False)\n",
    "        top_k_contains_pump: bool = df_pump.iloc[:K][\"is_pumped\"].any()\n",
    "        top_k.append(top_k_contains_pump)\n",
    "\n",
    "    top_k_vals.append(\n",
    "        sum(top_k) / len(top_k)\n",
    "    )\n",
    "        \n",
    "top_k_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fi = pd.DataFrame({\n",
    "    \"features\": reg_cols,\n",
    "    \"feature_importance\": model.feature_importances_\n",
    "})\n",
    "\n",
    "df_fi = df_fi.sort_values(by=\"feature_importance\", ascending=False)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax1, ax2 = axs\n",
    "\n",
    "sns.barplot(\n",
    "    data=df_fi.iloc[:50], x=\"feature_importance\", y=\"features\", ax=ax1\n",
    ")\n",
    "sns.barplot(\n",
    "    data=df_fi.iloc[-50:], x=\"feature_importance\", y=\"features\", ax=ax2\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
