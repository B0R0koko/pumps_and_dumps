{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from typing import *\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "ROOT_DIR = Path(os.getcwd()).parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 138)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\n",
    "    os.path.join(ROOT_DIR, \"data/datasets/train_26_05.parquet\")\n",
    ")\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "df[\"pump_hash\"] = df[\"pumped_ticker\"] + df[\"pump_time\"]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, precision_recall_curve, auc\n",
    "from functools import partial\n",
    "\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import gc\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(data=df_train[num_cols], label=df_train[\"is_pumped\"])\n",
    "dtest = xgb.DMatrix(data=df_test[num_cols], label=df_test[\"is_pumped\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_objective(\n",
    "    trial: optuna.Trial, df: pd.DataFrame, reg_cols: List[str], target: str, fold: TimeSeriesSplit\n",
    ") -> float:\n",
    "    xgb_params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": [\"logloss\"],\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 1, 300)\n",
    "    }\n",
    "\n",
    "    auc_scores = []\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for train_idx, val_idx in fold.split(df[reg_cols], df[target]):\n",
    "        # split data to train and validation sets\n",
    "        df_train, df_val = df.iloc[train_idx], df.iloc[val_idx]\n",
    "        # train on train subset and use validation set to evaluate the model\n",
    "        dtrain = xgb.DMatrix(df_train[reg_cols], label=df_train[target])\n",
    "        dval = xgb.DMatrix(df_val[reg_cols], label=df_val[target])\n",
    "        \n",
    "        evals_result = {}\n",
    "        \n",
    "        # Fit the model with early stopping\n",
    "        model = xgb.train(\n",
    "            xgb_params, dtrain=dtrain, \n",
    "            evals=[(dtrain, \"train\"), (dval, \"val\")],\n",
    "            num_boost_round=500, early_stopping_rounds=20,\n",
    "            verbose_eval=False, evals_result=evals_result\n",
    "        )\n",
    "        \n",
    "        y_proba = model.predict(dval)\n",
    "        y_pred = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "        precision, recall, _ = precision_recall_curve(y_true=df_val[\"is_pumped\"], probas_pred=y_proba)\n",
    "        auc_score: float = auc(recall, precision)\n",
    "\n",
    "        # _, f1_minority = f1_score(y_pred=y_pred, y_true=df_val[target], average=None)\n",
    "        \n",
    "        # get the best auc_score validation set\n",
    "        auc_scores.append(auc_score)\n",
    "        \n",
    "        trial.report(auc_score, i)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        \n",
    "        del model, dtrain, dval, y_pred\n",
    "        _ = gc.collect()\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    return np.mean(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "study_xgboost = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5)\n",
    ")\n",
    "\n",
    "study_xgboost.optimize(\n",
    "    partial(xgboost_objective, df=df_train, reg_cols=num_cols, target=\"is_pumped\", fold=fold), \n",
    "    n_trials=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": [\"logloss\"]\n",
    "}\n",
    "\n",
    "params.update(study_xgboost.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with early stopping on validation set\n",
    "model = xgb.train(\n",
    "    params, dtrain=dtrain, \n",
    "    num_boost_round=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = model.predict(dtest)\n",
    "y_pred = (y_proba >= 0.1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "print(classification_report(y_true=df_test[\"is_pumped\"], y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=df_test[\"is_pumped\"], y_pred=y_pred)\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc, PrecisionRecallDisplay\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_true=df_test[\"is_pumped\"], probas_pred=y_proba)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "PrecisionRecallDisplay(\n",
    "    precision=precision, recall=recall\n",
    ").plot(ax=ax)\n",
    "\n",
    "f_scores = np.linspace(0.1, 0.8, num=10)\n",
    "lines, labels = [], []\n",
    "\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y = f_score * x / (2 * x - f_score)\n",
    "    (l,) = ax.plot(x[y >= 0], y[y >= 0], color=\"blue\", alpha=0.2)\n",
    "    ax.annotate(\"f1={0:0.1f}\".format(f_score), xy=(0.9, y[45] + 0.02))\n",
    "\n",
    "plt.title(f\"AUC score: {round(auc(recall, precision), 5)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP-K metric\n",
    "df_test[\"proba\"] = y_proba\n",
    "\n",
    "top_k_vals = []\n",
    "\n",
    "for K in [1, 5, 10, 20, 40, 60]: \n",
    "\n",
    "    top_k: List[bool] = []\n",
    "\n",
    "    for pump_hash, df_pump in df_test.groupby(\"pump_hash\"):\n",
    "        df_pump = df_pump.sort_values(by=\"proba\", ascending=False)\n",
    "        top_k_contains_pump: bool = df_pump.iloc[:K][\"is_pumped\"].any()\n",
    "        top_k.append(top_k_contains_pump)\n",
    "\n",
    "    top_k_vals.append(\n",
    "        sum(top_k) / len(top_k)\n",
    "    )\n",
    "        \n",
    "top_k_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.get_score(importance_type=\"gain\")\n",
    "\n",
    "df_res = pd.DataFrame({\n",
    "    \"features\": importances.keys(),\n",
    "    \"value\": importances.values()\n",
    "})\n",
    "\n",
    "df_res = df_res.sort_values(by=\"value\", ascending=False).iloc[:30]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "sns.barplot(\n",
    "    data=df_res, x=\"value\", y=\"features\", ax=ax\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostClassifier\n",
    "\n",
    "\n",
    "def catboost_objective(\n",
    "    trial: optuna.Trial, df: pd.DataFrame, reg_cols: List[str], target: str, fold: TimeSeriesSplit\n",
    ") -> float:\n",
    "    params = {\n",
    "        \"objective\": \"Logloss\",\n",
    "        \"eval_metric\": \"Logloss\",\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "        \"class_weights\": [1, trial.suggest_float(\"scale_pos_weight\", 1, 300)],\n",
    "    }\n",
    "\n",
    "    auc_scores = []\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for train_idx, val_idx in fold.split(df[reg_cols], df[target]):\n",
    "        # split data to train and validation sets\n",
    "        df_train, df_val = df.iloc[train_idx], df.iloc[val_idx]\n",
    "        # train on train subset and use validation set to evaluate the model\n",
    "        train = Pool(data=df_train[reg_cols], label=df_train[target], cat_features=[\"num_prev_pumps\"])\n",
    "        val = Pool(data=df_val[reg_cols], label=df_val[target], cat_features=[\"num_prev_pumps\"])\n",
    "        \n",
    "        # Fit the model with early stopping\n",
    "        model = CatBoostClassifier(\n",
    "            **params, \n",
    "            task_type=\"GPU\",\n",
    "            devices=\"0\",\n",
    "            iterations=500,\n",
    "            early_stopping_rounds=20,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            train, eval_set=val\n",
    "        )\n",
    "        \n",
    "        y_proba = model.predict_proba(val)[:, 1]\n",
    "        y_pred = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "        precision, recall, _ = precision_recall_curve(y_true=df_val[\"is_pumped\"], probas_pred=y_proba)\n",
    "        auc_score: float = auc(recall, precision)\n",
    "\n",
    "        # _, f1_minority = f1_score(y_pred=y_pred, y_true=df_val[target], average=None)\n",
    "        \n",
    "        # get the best auc_score validation set\n",
    "        auc_scores.append(auc_score)\n",
    "        \n",
    "        trial.report(auc_score, i)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        \n",
    "        del model, train, val, y_pred\n",
    "        _ = gc.collect()\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    return np.mean(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_catboost = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5)\n",
    ")\n",
    "\n",
    "study_catboost.optimize(\n",
    "    partial(catboost_objective, df=df_train, reg_cols=num_cols, target=\"is_pumped\", fold=fold), \n",
    "    n_trials=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Pool(data=df_train[num_cols], label=df_train[\"is_pumped\"])\n",
    "test = Pool(data=df_test[num_cols], label=df_test[\"is_pumped\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_params = {\n",
    "    \"objective\": \"Logloss\",\n",
    "    \"task_type\": \"GPU\"\n",
    "}\n",
    "\n",
    "cb_params.update(study_catboost.best_params)\n",
    "cb_params[\"class_weights\"] = [1, study_catboost.best_params[\"scale_pos_weight\"]]\n",
    "\n",
    "del cb_params[\"scale_pos_weight\"]\n",
    "\n",
    "model = CatBoostClassifier(**cb_params, iterations=300)\n",
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = model.predict_proba(test)\n",
    "y_pred = y_proba[:, 1] >= 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=df_test[\"is_pumped\"], y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=df_test[\"is_pumped\"], y_pred=y_pred)\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_true=df_test[\"is_pumped\"], probas_pred=y_proba[:, 1])\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "PrecisionRecallDisplay(\n",
    "    precision=precision, recall=recall\n",
    ").plot(ax=ax)\n",
    "\n",
    "f_scores = np.linspace(0.1, 0.8, num=10)\n",
    "lines, labels = [], []\n",
    "\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y = f_score * x / (2 * x - f_score)\n",
    "    (l,) = ax.plot(x[y >= 0], y[y >= 0], color=\"blue\", alpha=0.2)\n",
    "    ax.annotate(\"f1={0:0.1f}\".format(f_score), xy=(0.9, y[45] + 0.02))\n",
    "\n",
    "plt.title(f\"AUC score: {round(auc(recall, precision), 5)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP-K metric\n",
    "df_test[\"proba\"] = y_proba[:, 1]\n",
    "\n",
    "top_k_vals = []\n",
    "\n",
    "for K in [1, 5, 10, 20, 40, 60]: \n",
    "\n",
    "    top_k: List[bool] = []\n",
    "\n",
    "    for pump_hash, df_pump in df_test.groupby(\"pump_hash\"):\n",
    "        df_pump = df_pump.sort_values(by=\"proba\", ascending=False)\n",
    "        top_k_contains_pump: bool = df_pump.iloc[:K][\"is_pumped\"].any()\n",
    "        top_k.append(top_k_contains_pump)\n",
    "\n",
    "    top_k_vals.append(\n",
    "        sum(top_k) / len(top_k)\n",
    "    )\n",
    "\n",
    "top_k_vals       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fi = pd.DataFrame({\n",
    "    \"features\": num_cols,\n",
    "    \"feature_importance\": model.feature_importances_\n",
    "})\n",
    "\n",
    "df_fi = df_fi.sort_values(by=\"feature_importance\", ascending=False)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax1, ax2 = axs\n",
    "\n",
    "sns.barplot(\n",
    "    data=df_fi.iloc[:50], x=\"feature_importance\", y=\"features\", ax=ax1\n",
    ")\n",
    "sns.barplot(\n",
    "    data=df_fi.iloc[-50:], x=\"feature_importance\", y=\"features\", ax=ax2\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
