{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Features 14/06/2024</h4>\n",
    "\n",
    "<p>Yet another revision of features with latest ideas of mine</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from dataclasses import dataclass\n",
    "from typing import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "ROOT_DIR = Path(os.getcwd()).parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PumpEvent:\n",
    "    pump_id: int\n",
    "    ticker: str\n",
    "    time: str\n",
    "    exchange: str\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.time: pd.Timestamp = pd.Timestamp(self.time)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Pump event: {self.ticker} - {str(self.time)} on {self.exchange}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is organized by days\n",
    "pump = PumpEvent(\n",
    "    pump_id=1, ticker=\"AGIXBTC\", time=\"2022-08-14 16:00:05\", exchange=\"binance\"\n",
    ")\n",
    "\n",
    "def load_data(pump: PumpEvent, lookback_delta: timedelta) -> pd.DataFrame:\n",
    "\n",
    "    end: pd.Timestamp = pump.time.round(\"1h\") - timedelta(hours=1)\n",
    "    start: pd.Timestamp = end - lookback_delta\n",
    "    \n",
    "    date_range: List[pd.Timestamp] = pd.date_range(\n",
    "        start=start,\n",
    "        end=end, freq=\"D\",\n",
    "        inclusive=\"both\"\n",
    "    ).tolist()\n",
    "\n",
    "    df: pd.DataFrame = pd.DataFrame()\n",
    "\n",
    "    for date in tqdm(date_range):\n",
    "        file_name: str = f\"{pump.ticker}-trades-{date.date()}.parquet\"\n",
    "        df_date: pd.DataFrame = pd.read_parquet(\n",
    "            os.path.join(ROOT_DIR, f\"data/trades_parquet/{pump.exchange}/{pump.ticker}\", file_name)\n",
    "        )\n",
    "        \n",
    "        df = pd.concat([df, df_date])\n",
    "\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"], unit=\"ms\")\n",
    "    df = df[(df[\"time\"] >= start) & (df[\"time\"] <= end)].reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Load data</h4>\n",
    "\n",
    "<p>We will need at least a month worth of data as I will want to compare metrics computed in the last 24h-7d before the pump with past values</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:00<00:00, 88.65it/s]\n"
     ]
    }
   ],
   "source": [
    "df = load_data(pump=pump, lookback_delta=timedelta(days=30))\n",
    "df[\"quote\"] = df[\"qty\"] * df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>price_first</th>\n",
       "      <th>price_last</th>\n",
       "      <th>price_max</th>\n",
       "      <th>price_min</th>\n",
       "      <th>qty_sign</th>\n",
       "      <th>qty_abs</th>\n",
       "      <th>quote_sign</th>\n",
       "      <th>quote_abs</th>\n",
       "      <th>is_long</th>\n",
       "      <th>quote_long</th>\n",
       "      <th>quote_short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-15 15:00:02.422</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-2437.0</td>\n",
       "      <td>2437.0</td>\n",
       "      <td>-0.004240</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-15 15:00:02.434</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>275.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  price_first  price_last  price_max  price_min  \\\n",
       "0 2022-07-15 15:00:02.422     0.000002    0.000002   0.000002   0.000002   \n",
       "1 2022-07-15 15:00:02.434     0.000002    0.000002   0.000002   0.000002   \n",
       "\n",
       "   qty_sign  qty_abs  quote_sign  quote_abs  is_long  quote_long  quote_short  \n",
       "0   -2437.0   2437.0   -0.004240   0.004240    False    0.000000      0.00424  \n",
       "1     275.0    275.0    0.000479   0.000479     True    0.000479      0.00000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"qty_sign\"] = (1 - 2 * df[\"isBuyerMaker\"]) * df[\"qty\"]\n",
    "df[\"quote_sign\"] = (1 - 2 * df[\"isBuyerMaker\"]) * df[\"quote\"]\n",
    "\n",
    "# Aggregate by time into rush orders\n",
    "df_trades: pd.DataFrame = df.groupby(\"time\").agg(\n",
    "    price_first=(\"price\", \"first\"),\n",
    "    price_last=(\"price\", \"last\"),\n",
    "    price_max=(\"price\", \"max\"),\n",
    "    price_min=(\"price\", \"min\"),\n",
    "    qty_sign=(\"qty_sign\", \"sum\"),\n",
    "    qty_abs=(\"qty\", \"sum\"),\n",
    "    quote_sign=(\"quote_sign\", \"sum\"),\n",
    "    quote_abs=(\"quote\", \"sum\"),\n",
    ")\n",
    "\n",
    "df_trades[\"is_long\"] = df_trades[\"qty_sign\"] >= 0 # is buyer\n",
    "df_trades[\"quote_long\"] = df_trades[\"quote_abs\"] * df_trades[\"is_long\"] # quote volume for longs\n",
    "df_trades[\"quote_short\"] = df_trades[\"quote_abs\"] * ~df_trades[\"is_long\"] # quote volume for shorts\n",
    " \n",
    "df_trades = df_trades.reset_index()\n",
    "df_trades.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Slippages</h4>\n",
    "\n",
    "$$\n",
    "\\text{Slippage Loss} = \\underbrace{\\sum_{i=1}^{N}{\\text{qty\\_sign}_i} \\cdot P_i}_{\\text{Quote actually spent}} \\: - \\underbrace{\\sum_{i=1}^N{\\text{qty\\_sign}_i} \\cdot P_0}_{\\substack{\\text{Quote could have been spent} \\\\ \\text{if filled at best price}}}\n",
    "$$\n",
    "\n",
    "This formula calculates the slippage loss as the difference between quote we actually spent and quote amount we would have paid if we were able to execute at the best bid or ask price (depending on the side of the trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate slippages\n",
    "df_trades[\"quote_slippage_abs\"] = np.abs(\n",
    "    df_trades[\"quote_abs\"] - df_trades[\"qty_abs\"] * df_trades[\"price_first\"]\n",
    ")\n",
    "df_trades[\"quote_slippage_sign\"] = df_trades[\"quote_slippage_abs\"] * np.sign(df_trades[\"qty_sign\"])\n",
    "df_trades[\"quote_slippage_long\"] = df_trades[\"quote_slippage_abs\"] * df_trades[\"is_long\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Hourly candlestick features</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly_candles: pd.DataFrame = (\n",
    "    df_trades\n",
    "    .resample(on=\"time\", rule=\"1h\", closed=\"left\")\n",
    "    .agg(\n",
    "        open=(\"price_first\", \"first\"),\n",
    "        close=(\"price_last\", \"last\"),\n",
    "        low=(\"price_min\", \"min\"),\n",
    "        high=(\"price_max\", \"max\"),\n",
    "        volume_qty_abs=(\"qty_abs\", \"sum\"), # absolute volume in base asset\n",
    "        volume_quote_abs=(\"quote_abs\", \"sum\"), # absolute volume in quote asset\n",
    "        volume_quote_abs_long=(\"quote_long\", \"sum\"),\n",
    "        num_trades=(\"is_long\", \"count\"), \n",
    "        num_trades_long=(\"is_long\", \"sum\"), \n",
    "        quote_slippage_abs=(\"quote_slippage_abs\", \"sum\"), # slippage loss incurred by both buy and sell sides\n",
    "        quote_slippage_abs_long=(\"quote_slippage_long\", \"sum\") # quote slippage incurred by longs\n",
    "    )\n",
    ").reset_index()\n",
    "\n",
    "df_hourly_candles[\"log_return\"] = np.log(\n",
    "    df_hourly_candles[\"close\"] / df_hourly_candles[\"close\"].shift(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume_qty_abs</th>\n",
       "      <th>volume_quote_abs</th>\n",
       "      <th>volume_quote_abs_long</th>\n",
       "      <th>num_trades</th>\n",
       "      <th>num_trades_long</th>\n",
       "      <th>quote_slippage_abs</th>\n",
       "      <th>quote_slippage_abs_long</th>\n",
       "      <th>log_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>2022-08-14 14:00:00</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2358663.0</td>\n",
       "      <td>6.093561</td>\n",
       "      <td>2.671495</td>\n",
       "      <td>223</td>\n",
       "      <td>133</td>\n",
       "      <td>0.010421</td>\n",
       "      <td>0.008779</td>\n",
       "      <td>0.031131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   time      open     close       low      high  \\\n",
       "719 2022-08-14 14:00:00  0.000003  0.000003  0.000003  0.000003   \n",
       "\n",
       "     volume_qty_abs  volume_quote_abs  volume_quote_abs_long  num_trades  \\\n",
       "719       2358663.0          6.093561               2.671495         223   \n",
       "\n",
       "     num_trades_long  quote_slippage_abs  quote_slippage_abs_long  log_return  \n",
       "719              133            0.010421                 0.008779    0.031131  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hourly_candles.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Binned features</h4>\n",
    "\n",
    "<p>Following methodology of Xu and Livshits 2019, we calculate overall log return and hourly log returns volatility over different windows</p>\n",
    "\n",
    "We will scale absolute features like volumes and quote quantities by long run std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_ub: pd.Timestamp = pump.time.round(\"1h\") - timedelta(hours=1)\n",
    "\n",
    "# long run mean and std of volumes in base and quote\n",
    "df_hourly_lr: pd.DataFrame = df_hourly_candles[\n",
    "    df_hourly_candles[\"volume_quote_abs\"] <= df_hourly_candles[\"volume_quote_abs\"].quantile(.99)\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Log returns and volume features</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_offsets: List[int] = [1, 6, 24, 48, 72, 7*24, 14*24]\n",
    "\n",
    "hourly_features: Dict[str, float] = {}\n",
    "\n",
    "for offset in hour_offsets:\n",
    "    df_window: pd.DataFrame = df_hourly_candles[df_hourly_candles[\"time\"] >= time_ub - timedelta(hours=offset)].copy()\n",
    "    \n",
    "    hourly_features[f\"overall_return_{offset}h\"] = (df_window[\"log_return\"] + 1).prod() # overall return if held for the whole window up to the last hour\n",
    "\n",
    "    # Scaled volumes in base and quote assets\n",
    "    hourly_features[f\"volume_quote_abs_zscore_{offset}h_30d\"] = (\n",
    "        (df_window[\"volume_quote_abs\"].mean() - df_hourly_lr[\"volume_quote_abs\"].mean()) / df_hourly_lr[\"volume_quote_abs\"].std()\n",
    "    )\n",
    "\n",
    "    # hourly_features[f\"num_trades_long_share_{offset}h\"] = df_window[\"num_trades_long\"].sum() / df_window[\"num_trades\"].sum()\n",
    "    hourly_features[f\"volume_quote_long_share_{offset}h\"] = df_window[\"volume_quote_abs_long\"].sum() / df_window[\"volume_quote_abs\"].sum()\n",
    "\n",
    "    if offset == 1:\n",
    "        continue\n",
    "    # Hourly log returns volatility scaled by long run volatility\n",
    "    hourly_features[f\"log_return_std_{offset}h_30d\"] = np.log(df_window[\"log_return\"].std() / df_hourly_lr[\"log_return\"].std())\n",
    "    # hourly log returns mean scaled by long run std -> z-score\n",
    "    hourly_features[f\"log_return_zscore_{offset}h_30d\"] = df_window[\"log_return\"].mean() / df_hourly_lr[\"log_return\"].std() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hourly_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Slippage features</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slippage_features: Dict[str, float] = {}\n",
    "\n",
    "df_hourly_candles_120h: pd.DataFrame = df_hourly_candles[\n",
    "    df_hourly_candles[\"time\"] >= time_ub - timedelta(hours=120)\n",
    "].copy()\n",
    "\n",
    "hour_offsets: List[int] = [1, 6, 24, 48, 72]\n",
    "\n",
    "for offset in hour_offsets:\n",
    "    df_window: pd.DataFrame = df_hourly_candles[df_hourly_candles[\"time\"] >= time_ub - timedelta(hours=offset)].copy()\n",
    "    # Share of overall slippages of this time window in 120hours\n",
    "    slippage_features[f\"quote_slippage_abs_share_{offset}h_120h\"] = (\n",
    "        df_window[\"quote_slippage_abs\"].sum() / df_hourly_candles_120h[\"quote_slippage_abs\"].sum()\n",
    "    )\n",
    "\n",
    "len(slippage_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Imbalance features</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalance_features: Dict[str, float] = {}\n",
    "\n",
    "for offset in hour_offsets:\n",
    "    df_window: pd.DataFrame = df_trades[df_trades[\"time\"] >= time_ub - timedelta(hours=offset)].copy()\n",
    "    # Volume imbalance ratio to see if there is more buying pressure\n",
    "    imbalance_features[f\"quote_imbalance_ratio_{offset}h\"] = df_window[\"quote_sign\"].sum() / df_window[\"quote_abs\"].sum()\n",
    "    # Imbalance ratio in slippages to see if there is skew towards long slippages\n",
    "    imbalance_features[f\"quote_slippage_imbalance_ratio_{offset}h\"] = df_window[\"quote_slippage_sign\"].sum() / df_window[\"quote_slippage_abs\"].sum()\n",
    "\n",
    "len(imbalance_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>EVT features</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trades[\n",
    "    df_trades[\"time\"] >= time_ub - timedelta(days=3)\n",
    "].plot.scatter(x=\"time\", y=\"quote_sign\", figsize=(20, 4))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import powerlaw\n",
    "\n",
    "\n",
    "evt_features: Dict[str, float] = {}\n",
    "\n",
    "\n",
    "for offset in hour_offsets:\n",
    "    df_window: pd.DataFrame = df_trades[df_trades[\"time\"] >= time_ub - timedelta(hours=offset)].copy()\n",
    "\n",
    "    evt_features[f\"quote_abs_powerlaw_alpha_{offset}h\"] = powerlaw.fit(\n",
    "        df_window[df_window[\"quote_abs\"] >= df_window[\"quote_abs\"].quantile(.99)][\"quote_abs\"]\n",
    "    )[0]\n",
    "\n",
    "len(evt_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Powerlaw manual estimation</h4>\n",
    "\n",
    "We want to use EVT features that could allow us to capture heavy tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = df_trades[\"quote_abs\"].quantile(.99)\n",
    "    \n",
    "# Filter tails\n",
    "df_filtered = df_trades[df_trades[\"quote_abs\"] >= cutoff].copy()\n",
    "\n",
    "# Create log space bins\n",
    "logbins = np.logspace(\n",
    "    np.log10(cutoff), np.log10(df_trades[\"quote_abs\"].max()), num=100\n",
    ")\n",
    "\n",
    "# Calculate PDF\n",
    "hist, bin_edges = np.histogram(df_filtered[\"quote_abs\"], bins=logbins, density=True)\n",
    "\n",
    "df_pdf = pd.DataFrame({\n",
    "    \"quote_abs\": bin_edges[:-1],\n",
    "    \"p\": hist\n",
    "})\n",
    "\n",
    "df_pdf = df_pdf[\n",
    "    (df_pdf[\"quote_abs\"] >= cutoff) & (df_pdf[\"p\"] != 0)\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "\n",
    "X = np.log10(df_pdf[\"quote_abs\"])\n",
    "X = add_constant(X)\n",
    "\n",
    "Y = np.log10(df_pdf[\"p\"])\n",
    "\n",
    "model = OLS(\n",
    "    endog=Y, exog=X\n",
    ").fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept, slope = model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(13, 6))\n",
    "ax1, ax2 = axs\n",
    "\n",
    "# First plot\n",
    "X = np.log10(df_pdf[\"quote_abs\"])\n",
    "Y = np.log10(df_pdf[\"p\"])\n",
    "\n",
    "ax1.scatter(X, Y, alpha=.3, label=\"Observed PDF\")\n",
    "\n",
    "Y = intercept + slope * X\n",
    "\n",
    "ax1.set_title(\"Log scaled. Powerlaw fitted to observed data\")\n",
    "ax1.set_xlabel(\"log(quote_abs)\")\n",
    "ax1.set_ylabel(\"log(Estimated PDF)\")\n",
    "\n",
    "ax1.plot(X, Y, color=\"red\", label=\"Fitted PDF\")\n",
    "ax1.legend()\n",
    "\n",
    "# Second plot\n",
    "X = df_pdf[\"quote_abs\"]\n",
    "Y = df_pdf[\"p\"]\n",
    "\n",
    "a = 10**intercept\n",
    "b = slope\n",
    "\n",
    "ax2.scatter(X, Y, alpha=.3, label=\"Observed PDF\")\n",
    "ax2.plot(X, a*X**b, color=\"red\", label=\"Fitted PDF\")\n",
    "\n",
    "ax2.set_title(\"Powerlaw fitted to observed data\")\n",
    "ax2.set_xlabel(\"quote_abs\")\n",
    "ax2.set_ylabel(\"Estimated PDF\")\n",
    "\n",
    "ax2.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"imgs/powerlaw.png\", transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\log{f} = \\underbrace{\\log{\\alpha}}_{\\text{intercept}} + \\underbrace{(\\alpha - 1)}_{\\text{slope}}\\log{x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "X = df_pdf[\"quote_abs\"]\n",
    "Y = df_pdf[\"p\"]\n",
    "\n",
    "a = 10**intercept\n",
    "b = slope\n",
    "\n",
    "plt.scatter(X, Y, alpha=.3, label=\"Observed PDF\")\n",
    "\n",
    "plt.plot(X, a*X**b, color=\"red\", label=\"Fitted PDF\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
